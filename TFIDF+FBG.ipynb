{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86a50f8",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d21b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #=> stop words removal \n",
    "#from nltk import pos_tag #=> for defining part of speech \n",
    "from nltk.stem.porter import PorterStemmer #=> stemming word into its root\n",
    "from nltk.stem.wordnet import WordNetLemmatizer #=> Lemmatizing variants of word to its original form\n",
    "#from nltk.tokenize import word_tokenize , sent_tokenize #=> for tokenizing sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102a297f",
   "metadata": {},
   "source": [
    "## 1. Normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd02cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"storing storage to store\"\n",
    "text = text.lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab854b2",
   "metadata": {},
   "source": [
    "## 2. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9591352",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = word_tokenize(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81fe57",
   "metadata": {},
   "source": [
    "## 3. Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bbbd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#=> Remove stop words \n",
    "words = [w for w in text if w not in stopwords.words(\"english\")]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7031e7",
   "metadata": {},
   "source": [
    "## 4. Stem/Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5224f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=> Stemming and Lemmatization \n",
    "#-> stemmer : returns Nouns and verbs to its root \n",
    "# branched , branches , branching -> branch \n",
    "stemmed = [PorterStemmer().stem(w) for w in words]\n",
    "print(stemmed)\n",
    "#-> Lemmatizer : another technique to return word's variant to its root \n",
    "# was , were , is -> be (uses a dictionairy)\n",
    "# -> It is like the stemmer in most of stuff except it uses a dict + returns a meaningful word\n",
    "lemmatized = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc9ccb4",
   "metadata": {},
   "source": [
    "## Keyword Matching score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e51b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_matching_score(student_answer, keywords):\n",
    "    \"\"\"\n",
    "    Calculate the score of a student's answer based on keyword matching.\n",
    "    \n",
    "    Parameters:\n",
    "    - student_answer (str): The student's answer.\n",
    "    - model_answer (str): The model answer.\n",
    "    - keywords (list of str): Keywords to match.\n",
    "    \n",
    "    Returns:\n",
    "    - score (float): The keyword matching score.\n",
    "    \"\"\"\n",
    "    # Convert both answers and keywords to lowercase for case-insensitive matching\n",
    "    student_answer_lower = student_answer.lower()\n",
    "    \n",
    "    keywords_lower = [keyword.lower() for keyword in keywords]\n",
    "    \n",
    "    # Initialize score\n",
    "    score = 0\n",
    "    \n",
    "    # Calculate score based on keyword matching\n",
    "    for keyword in keywords_lower:\n",
    "        if keyword in student_answer_lower:\n",
    "            score += 1\n",
    "    \n",
    "    # Normalize score by dividing by the total number of keywords\n",
    "    if keywords_lower:\n",
    "        score /= len(keywords_lower)\n",
    "    \n",
    "    return score\n",
    "\n",
    "student_answer = \"By using a dynamic programming approach along with graph ds\"\n",
    "keywords = [\"dynamic programming\", \"bfs\", \"graph\"]\n",
    "\n",
    "score = keyword_matching_score(student_answer, keywords)\n",
    "print(\"Keyword Matching Score:\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6007ad26",
   "metadata": {},
   "source": [
    "## Already made TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a052170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def tfidf_similarity(student_answer, model_answer):\n",
    "    \"\"\"\n",
    "    Calculate the TF-IDF similarity score between a student's answer and a model answer.\n",
    "    \n",
    "    Parameters:\n",
    "    - student_answer (str): The student's answer.\n",
    "    - model_answer (str): The model answer.\n",
    "    \n",
    "    Returns:\n",
    "    - similarity_score (float): The TF-IDF similarity score.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Create a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer(input='content',analyzer='word',\n",
    "                                 decode_error='ignore')\n",
    "\n",
    "    # Fit the vectorizer on the model answer\n",
    "    vectorizer.fit([model_answer])\n",
    "\n",
    "    # Transform both answers into TF-IDF vectors\n",
    "    tfidf_matrix = vectorizer.transform([student_answer, model_answer])\n",
    "\n",
    "    # Calculate cosine similarity between the TF-IDF vectors\n",
    "    similarity_score = cosine_similarity(tfidf_matrix)[0, 1]\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "# Example usage:\n",
    "model_answer = \"A data structure is a storage format that defines the way data is stored, organized, and manipulated. Like trees , graphs and lists\"\n",
    "student_answer = \"A data structure is a format for storage , ogranizing and manipulating data. some examples of data structures are trees , graphs and lists\"\n",
    "\n",
    "tfidf_score = tfidf_similarity(student_answer, model_answer)\n",
    "print(\"TF-IDF Similarity Score:\", tfidf_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3dd1c1",
   "metadata": {},
   "source": [
    "## Manual Tf-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0df3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "Extra_Stop_Words = {\"the\",\",\",\"a\", \"an\", \"and\", \"or\", \"in\", \"on\", \"to\", \"is\", \"are\", \"was\", \"were\", \"am\", \"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"for\", \"of\", \"that\", \"this\", \"with\", \"as\", \"at\", \"by\", \"from\", \"up\", \"down\", \"out\", \"about\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"}\n",
    "STOP_WORDS = set(stopwords.words(\"english\"))\n",
    "STOP_WORDS = STOP_WORDS.union(Extra_Stop_Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16baf168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "def calculate_tf(document):\n",
    "    tf = {}\n",
    "    word_count = Counter(document)\n",
    "    total_words = len(document)\n",
    "    for word, count in word_count.items():\n",
    "        tf[word] = count / total_words\n",
    "    return tf\n",
    "\n",
    "def calculate_idf(documents):\n",
    "    k=0.3\n",
    "    total_documents = len(documents)\n",
    "    all_words = set(word for document in documents for word in document)\n",
    "    idf = {word: math.log((total_documents + k) / (1 + sum(1 for doc in documents if word in doc))) for word in all_words}\n",
    "    return idf\n",
    "\n",
    "\n",
    "def calculate_tfidf(tf, idf):\n",
    "    tfidf = {word: tf[word] * idf[word] for word in tf}\n",
    "    return tfidf\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = sum(vector1.get(word, 0) * vector2.get(word, 0) for word in set(vector1) & set(vector2))\n",
    "    \n",
    "    magnitude1 = math.sqrt(sum(value ** 2 for value in vector1.values()))\n",
    "    magnitude2 = math.sqrt(sum(value ** 2 for value in vector2.values()))\n",
    "    \n",
    "    if magnitude1 != 0 and magnitude2 != 0:\n",
    "        return dot_product / (magnitude1 * magnitude2)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# # to be used in the next cell\n",
    "# model_answer = \"A data structure is a storage format that defines the way data is stored, organized, and manipulated. Like trees , graphs and lists\"\n",
    "# student_answer = \"A data structure is a format for storage , ogranizing and manipulating data. some examples of data structures are trees , graphs and lists\"\n",
    "\n",
    "# tokens1 = [word for word in model_answer.lower().split() if word not in STOP_WORDS]\n",
    "# tokens2 = [word for word in student_answer.lower().split() if word not in STOP_WORDS]\n",
    "\n",
    "# documents = [tokens1, tokens2]\n",
    "# tf1 = calculate_tf(tokens1)\n",
    "# tf2 = calculate_tf(tokens2)\n",
    "# idf = calculate_idf(documents)\n",
    "# tfidf1 = calculate_tfidf(tf1, idf)\n",
    "# tfidf2 = calculate_tfidf(tf2, idf)\n",
    "# similarity_score = cosine_similarity(tfidf1, tfidf2)\n",
    "# print(\"Manual TF-IDF Similarity Score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2876363a",
   "metadata": {},
   "source": [
    "Mix Word2Vec and TF-IDF (Not Complete) and may be not the best solution so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea67a41",
   "metadata": {},
   "source": [
    "## We want to separate function implementation from the main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_answer = \"A data structure is a storage format that defines the way data is stored, organized, and manipulated. Like trees , graphs and lists\"\n",
    "student_answer = \"A data structure helps in storing, organizing and manipulating data. Examples of data structures include trees, graphs and lists.\"\n",
    "bad_student_answer = \"My grandma died two years ago and I have been feeling very sad since then.\"\n",
    "\n",
    "tokens1 = [word for word in model_answer.lower().split() if word not in STOP_WORDS]\n",
    "tokens2 = [word for word in student_answer.lower().split() if word not in STOP_WORDS]\n",
    "tokens3 = [word for word in bad_student_answer.lower().split() if word not in STOP_WORDS]\n",
    "\n",
    "keywords = [\"data structure\", \"storage\", \"format\", \"organize\", \"manipulate\", \"tree\", \"graph\", \"list\"]\n",
    "\n",
    "documents = [tokens1, tokens2]\n",
    "tf1 = calculate_tf(tokens1)\n",
    "tf2 = calculate_tf(tokens2)\n",
    "idf = calculate_idf(documents)\n",
    "tfidf1 = calculate_tfidf(tf1, idf)\n",
    "tfidf2 = calculate_tfidf(tf2, idf)\n",
    "similarity_score = cosine_similarity(tfidf1, tfidf2)\n",
    "keywords_score = keyword_matching_score(student_answer, keywords)\n",
    "print(\"Manual TF-IDF Similarity Score:\", similarity_score)\n",
    "print(\"Keyword Matching Score:\", keywords_score)\n",
    "try :\n",
    "    print(\"Final Score Metric 1 :\", 3.275 * (similarity_score * keywords_score) / (similarity_score + keywords_score))\n",
    "    print(\"Final Score Metric 2 :\", (similarity_score/keywords_score) * (similarity_score + keywords_score)/1.65)\n",
    "except ZeroDivisionError:\n",
    "    print(\"Final Score:\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_answer = \"A data structure is a storage format that defines the way data is stored, organized, and manipulated. Like trees , graphs and lists\"\n",
    "# student_answer = \"A data structure helps in storing, organizing and manipulating data. Examples of data structures include trees, graphs and lists.\"\n",
    "bad_student_answer = \"My grandma died two years ago to defines in a graph format and she fell from a tree while manipulated grandpa who was stored in a can.\"\n",
    "\n",
    "tokens1 = [word for word in model_answer.lower().split() if word not in STOP_WORDS]\n",
    "# tokens2 = [word for word in student_answer.lower().split() if word not in STOP_WORDS]\n",
    "tokens3 = [word for word in bad_student_answer.lower().split() if word not in STOP_WORDS]\n",
    "\n",
    "keywords = [\"data structure\", \"storage\", \"format\", \"organize\", \"manipulate\", \"tree\", \"graph\", \"list\"]\n",
    "\n",
    "documents = [tokens1, tokens3]\n",
    "tf1 = calculate_tf(tokens1)\n",
    "tf2 = calculate_tf(tokens3)\n",
    "idf = calculate_idf(documents)\n",
    "tfidf1 = calculate_tfidf(tf1, idf)\n",
    "tfidf2 = calculate_tfidf(tf2, idf)\n",
    "similarity_score = cosine_similarity(tfidf1, tfidf2)\n",
    "keywords_score = keyword_matching_score(bad_student_answer, keywords)\n",
    "print(\"Manual TF-IDF Similarity Score:\", similarity_score)\n",
    "print(\"Keyword Matching Score:\", keywords_score)\n",
    "try :\n",
    "    print(\"Final Score Metric 1 :\", 3.275 * (similarity_score * keywords_score) / (similarity_score + keywords_score))\n",
    "    print(\"Final Score Metric 2 :\", (similarity_score/keywords_score) * (similarity_score + keywords_score)/1.65)\n",
    "except ZeroDivisionError:\n",
    "    print(\"Final Score:\", 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099eab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_answer = \"A data structure is a storage format that defines the way data is stored, organized, and manipulated. Like trees , graphs and lists\"\n",
    "# student_answer = \"A data structure helps in storing, organizing and manipulating data. Examples of data structures include trees, graphs and lists.\"\n",
    "bad_student_answer = \"My grandma died two years ago she fell from a tree while manipulated grandpa\"\n",
    "\n",
    "tokens1 = [word for word in model_answer.lower().split() if word not in STOP_WORDS]\n",
    "# tokens2 = [word for word in student_answer.lower().split() if word not in STOP_WORDS]\n",
    "tokens3 = [word for word in bad_student_answer.lower().split() if word not in STOP_WORDS]\n",
    "\n",
    "keywords = [\"data structure\", \"storage\", \"format\", \"organize\", \"manipulate\", \"tree\", \"graph\", \"list\"]\n",
    "\n",
    "documents = [tokens1, tokens3]\n",
    "tf1 = calculate_tf(tokens1)\n",
    "tf2 = calculate_tf(tokens3)\n",
    "idf = calculate_idf(documents)\n",
    "tfidf1 = calculate_tfidf(tf1, idf)\n",
    "tfidf2 = calculate_tfidf(tf2, idf)\n",
    "similarity_score = cosine_similarity(tfidf1, tfidf2)\n",
    "keywords_score = keyword_matching_score(bad_student_answer, keywords)\n",
    "print(\"Manual TF-IDF Similarity Score:\", similarity_score)\n",
    "print(\"Keyword Matching Score:\", keywords_score)\n",
    "try :\n",
    "    print(\"Final Score Metric 1 :\", 3.275 * (similarity_score * keywords_score) / (similarity_score + keywords_score))\n",
    "    print(\"Final Score Metric 2 :\", (similarity_score/keywords_score) * (similarity_score + keywords_score)/1.65)\n",
    "except ZeroDivisionError:\n",
    "    print(\"Final Score:\", 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e10f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w mmkn b2a n3ml eh , n5ly el fraction yb2a kda badal ma yb2a rakam constant\n",
    "\n",
    "(similarity_score/keywords_score) * (similarity_score + keywords_score)/1.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b917e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #=> stop words removal \n",
    "from collections import Counter\n",
    "#from nltk import pos_tag #=> for defining part of speech \n",
    "from nltk.stem.porter import PorterStemmer #=> stemming word into its root\n",
    "from nltk.stem.wordnet import WordNetLemmatizer #=> Lemmatizing variants of word to its original form\n",
    "#from nltk.tokenize import word_tokenize , sent_tokenize #=> for tokenizing sentence\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "class AnswerEvaluator:\n",
    "    def __init__(self, model_answer, extra_stop_words=None):\n",
    "        self.model_answer = model_answer\n",
    "        self.STOP_WORDS = set(stopwords.words(\"english\"))\n",
    "        if extra_stop_words:\n",
    "            self.STOP_WORDS = self.STOP_WORDS.union(set(extra_stop_words))\n",
    "    \n",
    "    def calculate_tf(self, document):\n",
    "        tf = {}\n",
    "        word_count = Counter(document)\n",
    "        total_words = len(document)\n",
    "        for word, count in word_count.items():\n",
    "            tf[word] = count / total_words\n",
    "        return tf\n",
    "\n",
    "    def calculate_idf(self, documents):\n",
    "        k=0.3\n",
    "        total_documents = len(documents)\n",
    "        all_words = set(word for document in documents for word in document)\n",
    "        idf = {word: math.log((total_documents + k) / (1 + sum(1 for doc in documents if word in doc))) for word in all_words}\n",
    "        return idf\n",
    "\n",
    "    def calculate_tfidf(self, tf, idf):\n",
    "        tfidf = {word: tf[word] * idf[word] for word in tf}\n",
    "        return tfidf\n",
    "\n",
    "    def cosine_similarity(self, vector1, vector2):\n",
    "        dot_product = sum(vector1.get(word, 0) * vector2.get(word, 0) for word in set(vector1) & set(vector2))\n",
    "\n",
    "        magnitude1 = math.sqrt(sum(value ** 2 for value in vector1.values()))\n",
    "        magnitude2 = math.sqrt(sum(value ** 2 for value in vector2.values()))\n",
    "\n",
    "        if magnitude1 != 0 and magnitude2 != 0:\n",
    "            return dot_product / (magnitude1 * magnitude2)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def keyword_matching_score(self, student_answer, keywords):\n",
    "        student_answer_lower = student_answer.lower()\n",
    "        keywords_lower = [keyword.lower() for keyword in keywords]\n",
    "        score = 0\n",
    "        for keyword in keywords_lower:\n",
    "            if keyword in student_answer_lower:\n",
    "                score += 1\n",
    "        if keywords_lower:\n",
    "            score /= len(keywords_lower)\n",
    "        return score\n",
    "\n",
    "    def evaluate(self, student_answer, keywords):\n",
    "        tokens1 = [word for word in self.model_answer.lower().split() if word not in self.STOP_WORDS]\n",
    "        tokens2 = [word for word in student_answer.lower().split() if word not in self.STOP_WORDS]\n",
    "\n",
    "        # lemmatize , then stem \n",
    "        #tokens1 = [PorterStemmer().stem(WordNetLemmatizer().lemmatize(word)) for word in tokens1]\n",
    "        #tokens2 = [PorterStemmer().stem(WordNetLemmatizer().lemmatize(word)) for word in tokens2]\n",
    "\n",
    "        documents = [tokens1, tokens2]\n",
    "        tf1 = self.calculate_tf(tokens1)\n",
    "        tf2 = self.calculate_tf(tokens2)\n",
    "        idf = self.calculate_idf(documents)\n",
    "        tfidf1 = self.calculate_tfidf(tf1, idf)\n",
    "        tfidf2 = self.calculate_tfidf(tf2, idf)\n",
    "        similarity_score = self.cosine_similarity(tfidf1, tfidf2)\n",
    "        keywords_score = self.keyword_matching_score(student_answer, keywords)\n",
    "        try :\n",
    "            final_score = (similarity_score/keywords_score) * (similarity_score + keywords_score)/2\n",
    "        except ZeroDivisionError:\n",
    "            final_score = 0\n",
    "        return 1 if final_score > 1 else final_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackGenerator:\n",
    "    def __init__(self, evaluator, scores, stop_words):\n",
    "        self.evaluator = evaluator\n",
    "        self.scores = scores\n",
    "        self.stop_words = stop_words\n",
    "        self.feedback_message = \"Thanks for completing the interview. Here's your feedback:\\n\"\n",
    "\n",
    "    def generate_feedback_message(self):\n",
    "        technical_score = self.scores['technical']\n",
    "        linguistic_score = self.scores['linguistic']\n",
    "        behavioral_score = self.scores['behavioral']\n",
    "\n",
    "        if technical_score < 0.5:\n",
    "            self.feedback_message += \"Your technical proficiency needs improvement.\\n\"\n",
    "        elif technical_score < 0.7:\n",
    "            self.feedback_message += \"You're doing well in technical aspects, but there's room for improvement.\\n\"\n",
    "        elif technical_score < 1.0:\n",
    "            self.feedback_message += \"Your technical skills are impressive.\\n\"\n",
    "        \n",
    "\n",
    "        if linguistic_score < 0.5:\n",
    "            self.feedback_message += \"Your linguistic skills could be enhanced.\\n\"\n",
    "        elif linguistic_score < 0.7:\n",
    "            self.feedback_message += \"Your linguistic expression is satisfactory, but could be improved.\\n\"\n",
    "        elif linguistic_score < 1.0:\n",
    "            self.feedback_message += \"Your linguistic expression is excellent.\\n\"\n",
    "\n",
    "        if behavioral_score < 0.5:\n",
    "            self.feedback_message += \"Your behavioral conduct needs attention.\\n\"\n",
    "        elif behavioral_score < 0.7:\n",
    "            self.feedback_message += \"Your behavioral performance is acceptable, but could be better.\\n\"\n",
    "        elif behavioral_score < 1.0:\n",
    "            self.feedback_message += \"Your behavioral performance is commendable.\\n\"\n",
    "\n",
    "        # Additional feedback based on combined scores or other criteria can be added here\n",
    "        \n",
    "        return self.feedback_message\n",
    "    \n",
    "    def spider_graph_generator(self):\n",
    "    #split the dict into 2 lists\n",
    "        scores_dict = self.scores\n",
    "        scores = list(scores_dict.values())\n",
    "        \n",
    "        if max(scores) < 1:\n",
    "            scores = [round(score,0)*100 for score in scores]\n",
    "    \n",
    "        scores_dict = list(scores_dict.keys())\n",
    "\n",
    "\n",
    "        scores_dict_angles = np.linspace(0,2*np.pi,len(scores) , endpoint = False)\n",
    "        scores_dict_angles = np.concatenate((scores_dict_angles, [scores_dict_angles[0]]))\n",
    "        scores.append(scores[0])\n",
    "        scores_dict.append(scores_dict[0])\n",
    "        \n",
    "        fig=plt.figure(figsize=(6,6))\n",
    "        ax=fig.add_subplot(polar=True)\n",
    "        #basic plot\n",
    "        ax.plot(scores_dict_angles,scores, 'o--', color='g', linewidth=2, label='Scores')\n",
    "        #fill plot\n",
    "        ax.fill(scores_dict_angles, scores, alpha=0.25, color='g')\n",
    "        #Add labels\n",
    "        ax.set_thetagrids(scores_dict_angles * 180/np.pi, scores_dict)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc9b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test classes \n",
    "model_answer = \"A data structure is a storage format that defines the way data is stored, organized, and manipulated. Like trees , graphs and lists\"\n",
    "evaluator = AnswerEvaluator(model_answer, extra_stop_words=Extra_Stop_Words)\n",
    "student_answer = \"A data structure is a format for storage , ogranizing and manipulating data. some examples of data structures are trees , graphs and lists\"\n",
    "keywords = [\"data structure\", \"storage\", \"format\", \"organize\", \"manipulate\", \"tree\", \"graph\", \"list\"]\n",
    "technical_score = evaluator.evaluate(student_answer, keywords)\n",
    "print(\"Technical Score:\", technical_score)\n",
    "feedback_generator = FeedbackGenerator(evaluator, {\"technical\": technical_score, \"linguistic\": 0.7, \"behavioral\": 0.3}, stop_words=STOP_WORDS)\n",
    "feedback = feedback_generator.generate_feedback_message()\n",
    "print(feedback)\n",
    "feedback_generator.spider_graph_generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corner case ... \n",
    "model_answer = \"Graphs are not trees\"\n",
    "evaluator = AnswerEvaluator(model_answer, extra_stop_words=Extra_Stop_Words)\n",
    "student_answer = \"Graphs are trees\"\n",
    "keywords = [\"graph\", \"trees\", \"graphs\", \"tree\"]\n",
    "technical_score = evaluator.evaluate(student_answer, keywords)\n",
    "print(technical_score)\n",
    "feedback_generator = FeedbackGenerator(evaluator, {\"technical\": technical_score, \"linguistic\": 0.7, \"behavioral\": 0.6}, stop_words=STOP_WORDS)\n",
    "feedback = feedback_generator.generate_feedback_message()\n",
    "print(feedback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206eb3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lemmatizer and stemmer \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# test lemmatizer and stemmer on plural words \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "plural = [\"bringings\" , \"shops\", \"stores\" , \"storages\"]\n",
    "singular = [lemmatizer.lemmatize(word) for word in plural] #=> for plural \n",
    "print(singular)\n",
    "verbs_ =[\"bringing\" , \"shrunk\", \"stored\"]\n",
    "infinitive = [stemmer.stem(word) for word in singular] #=> for ing and ed verbs\n",
    "print(infinitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed79c33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
